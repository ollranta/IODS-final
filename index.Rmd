---
title: "Olli Rantanen, Final project, olli.a.rantanen@helsinki.fi. 1.3.2017" 
output: html_document
code_folding: show
---


```{r, echo=FALSE}
knitr::opts_chunk$set(error = TRUE)
```

# Abstract: 
I will focus on Boston dataset which is a built-in dataset in R-studio. The dataset consists of housing values of Boston and there are totally 14 variables and 506 observations. I wrangled the data only a little bit since it was basically in a perfect form allready. I thought I would need scaled variables but they did not come handy on any point. I will do linear regression analysis and multiple regression analysis. I will focus on 5 core variables which share the most positive/negative correlations with the crime variable. I will also show core summaries of the dataset, correlation matrix, scatter plots, residual plots and regression plots. Also there are some interpretation of the produced results. Our hypothesis was true, when median house value is lower on a neighbourhood the crime rate is higher and vice versa. This can be proved by looking our prediction model and linear regression chart.


# Some remarks about the project


Data from <https://stat.ethz.ch/R-manual/R-devel/library/MASS/html/Boston.html>

Data Wrangling<https://github.com/ollranta/IODS-final/blob/master/boston_datawrangle.R>

First I was going to choose a new topic for the project but I had major problems deciding what to study and why. Since there is no way to tell that I would even find anything interesting about the dataset, I thought that it would be more interesting to find something new about the Boston dataset. I noticed that the data wrangling will be kind of short but I did not figure out any more ways that could help handling the data. 

Anyway our dataset is oldie but goldie as a dataset since we used it in chapter 4. The source for it are Harrison, D. and Rubinfeld, D.L. (1978) Hedonic prices and the demand for clean air. and J. Environ. Economics and Management 5, 81-102.Belsley D.A., Kuh, E. and Welsch, R.E. (1980) Regression Diagnostics. Identifying Influential Data and Sources of Collinearity. New York: Wiley. As you can see, the data is almost 40 years old and things may have changed quite a bit. The dataset consists of housing values in Boston which are indicated by 14 variables. Totally there are 506 observations of data. I did not have to do lots of data wrangling, since the data was allready in a pretty good form. However I changed the column names and also made a new dataset which has the scaled variables also. 

My core research question is how does crime variable behave on a linear regression analysis. For example my hypothesis is that places which have high crime will also lower median house values. 

I will use different variables in linear regression analysis to see how crime affect different things. 
I will do linear regression for the crime variable which is recommended by the instructions. I will also do multiple regression analysis with low and high correlation varibales to crime. have time I will use different variables in linear regression analysis to see how crime affect different things. 
The R does linear model y ~ x meaning y is target variable (grades) and x is the explanatory variable which is crime variable. 

So yeah let's have a look of our variables. 



```
colnames(Boston)


crime = per capita crime rate by town.

zone = proportion of residential land zoned for lots over 25,000 sq.ft.

industry =  proportion of non-retail business acres per town

charles = Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).

noc = nitrogen oxides concentration (parts per 10 million).

dwell_rooms = average number of rooms per dwelling

built_b1940 = proportion of owner-occupied units built prior to 1940.

distance =weighted mean of distances to five Boston employment centres.
    
highways = index of accessibility to radial highways.

property_tax = full-value property-tax rate per \$10,000.

pupil-teacher =  pupil-teacher ratio by town.

blacks = 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town.

lower = lower status of the population (percent).

median = median value of owner-occupied homes in \$1000
```
And here is the summary of the data variables.

```{r, echo=F}
library(MASS)
summary(Boston)
```


Let's use a correlation matrix to interpret the variables and their relationships. The pie charts are red by taking a look of the color and quantity of the wanted variables. For example crime rate seems to positively and pretty strongly correlated with highway variable. This interperation is made by looking that the pie is more than 50 % covered by blue.
```
correlation_plot <-cor(Boston) %>% round(digits=2)
corrplot(correlation_plot,  method="pie", type = "upper", cl.pos = "b", tl.pos = "d", tl.cex = 0.6)
```
![](corrplot1.png)

As we can see here there are also positive correlation with crime variable and property tax rate. Negative correlation between crime variable can be seen with median value of houses, black population and distance to Boston's employment centers. 

Then we can draw some scatterplots of the scaled variables. The scatterplot shows how these variables have distributed. 
```
pairs(~crime+zone+industry+charles +noc + dwell_rooms + built_b1940,data=Boston,
      main="Scatterplot of Boston variables")
```
![](scatter1.png)
```
pairs(~distance+highways+property_tax+pupil_teacher +blacks + lower + median,data=Boston,
      main="Scatterplot of Boston variables")
```
![](scatter2.png)

We can see how our variables vary a lot on the charts. They are not on a same scale on any amount. For example tax-rate and distance are on very different scale. Tax rate of property ranges on scale from 200 to 700 and distance on the other hand only varys from 2 to 12 on its scale. 

Visually clear and interesting explorations of the variables of interest in the data, from the point of view of your research question. Include interpretations of the distributions and relationships of the variables. Use captions to draw the reader's focus on the interesting parts of your tables and graphics.

Okay now I think we can move on to do the linear regression analysis. Linear regression analysis is used to find out if two (or more) variable's connection is statistically significant. This is done by visualizing the coeffecients between variables. We can interpret results from the produced chart. Also we can make predictions based on this and quantify the relationship between variables. If the line is going up, the coefficients are positive which means the variables are linearly related. If it's going down they are negative. 
Crime variable is target (dependent) variable on our analysis since we are trying to find out which variables linearly relate with crime variable. 



```
lm(formula = crime ~ ., data = Boston)
```
![](coeffi.jpg)

Okay so now we can look the linear models. I picked the explanatory variables which have high negative or positive correlation with the crime variable. So I'll use "highways", "property_tax", "median", "blacks", "distance". The graphs look pretty funky but that is just because there much more "non-crime" neighbourhood which make it look like that. Anyhow the linear models are right. The following models can described like this: If there line on the graph goes down there is evidence for non-linearity in the relationship between the variables. If it goes up, it means there is evidence for linearity between the relationship of the variables. The coefficent tables show us how much does the explanatory variable explain the variation of crime. For example distance is estimated to effect crime variable by -1.5. The p-values are so low because there are so many observations of data. 

```
qplot((Boston$crime), (Boston$distance), data = Boston) + geom_smooth(method = "lm")
model1 <- lm(Boston$crime ~ Boston$distance, data = Boston)
summary(model1)
```
![](dis.png)

![](dis.jpg)
```
qplot((Boston$crime), (Boston$highways), data = Boston) + geom_smooth(method = "lm")
model2 <- lm(Boston$crime ~ Boston$highways, data = Boston)
summary(model2)
```

![](high.png)

![](high.jpg)

```
qplot((Boston$crime), (Boston$property_tax), data = Boston) + geom_smooth(method = "lm")
model3 <- lm(Boston$crime ~ Boston$property_tax, data = Boston)
summary(model3)
```


![](tax.png)

![](tax.jpg)


```
qplot((Boston$crime), (Boston$median), data = Boston) + geom_smooth(method = "lm")
model4 <- lm(Boston$crime ~ Boston$median, data = Boston)
summary(model4)
```

![](medi.png)

![](medi.jpg)

```
qplot((Boston$crime), (Boston$blacks), data = Boston) + geom_smooth(method = "lm")
model5 <- lm(Boston$crime ~ Boston$blacks, data = Boston)
summary(model5)
```


![](bla.png)



![](bla.jpg)

Highways and property-tax rates do have linear relationships with crime variable. Distance, black and median variables do not have a linear relationship with the crime variable. This can be intercepted like this: When the property tax-rate is high the crimes happen more. Maybe this could be explained that the tax rates are high because there are much disturbances on the areas maybe. On the other linearity there seems to be that when median house price is low there is more crime. This explains that our hypothesis was right.



# Multiple regression analysis for both negative and positive correlations and Graphical model validation

I already explained what the coefficents and p value stand for below and now we can focus on multiple R-squared value, which is 0.2801 on model1 and 0.3923 on model2. These values tells us how does our model fit to observations. The bigger the value is, our model fits better to observations.

Then we can focus on our the plots below. Residuals mean prediction errors for our model and the plots are made for this. The first plot is calles residuals vs fitted residuals which   shows if the residuals have non-linear pattern. In our first model it does have a linear pattern which means our model works fine. The second one not so much.

Second plot is called normal Q-Q plot. Normal Q-Q plot shows if the residuals are normally distributed. If the residuals are not fitted at all on the straight line they are not normally distributed. On our case that is not the question and the residuals are pretty much normally distributed.

And last is residuals vs. leverage plot. We can interpret the extreme values with this plot. It tells us which points have the greatest influence on the regression. On this plot, focus is on the extreme cases and their influence to the regression analysis or the absence of this. When cases (dots) are outside of the red lide( cook's distance) the cases are influential to the regression results. Especially we that this is the case on the model2. 



```
my_model1 <- lm(Boston$crime ~ Boston$distance + Boston$blacks + Boston$median, data = Boston)

summary(my_model1)
```
![](multi1.jpg)

2 ? 3 grid panels which means 3 plots on 2 levels.

```
par(mfrow = c(2,2))
plot(my_model1, which = c(1,2,5))
```
![](my_model_residuals.png)

```
my_model2 <-lm(Boston$crime  ~ Boston$property_tax + Boston$highways, data = Boston)

summary(my_model2)
```
![](multi2.jpg)



2 ? 3 grid panels which means 3 plots on 2 levels.
```
par(mfrow = c(2,2))
plot(my_model2, which = c(1,2,5))
```
![](my_model2_residuals.png)

# Prediction 

Let's make a prediction of the median house value and amount of crime. Since we made our linear model we can use it to try new values for the such as: if house median value is 10 how much is the crime and so on. 

```
prediction <- lm(crime ~ median, data = Boston)
medians <- c("507" = 23,  "508" = 15)

new_data <- data.frame(median = medians)
predict(prediction, newdata  = new_data)
   507      508 
3.443858 6.349137
```
Based on the prediction our new observations number 507 would have per capita crime rate of 3.44 if its median household value is 23 000 dollars and the observation number 508 would have 6.34 crime rate per capita with median house value being 15 000 dollars. This shows how the prediction works.


# Conclusions and discussion
I could have maybe scale the crime variable on a different way but it showed the right things so maybe that was not necessary. I did not find any new ways to show the results of the multiple regression analysis since it is pretty straight forward to interpret from the summary. But I did include the residual plots and the explanations for them.
I did not find anything spectacular with my analysis but my hypothesis about the median house value and the amount of crime is right. Maybe this is a non-brainer but at least now I have a linear graph showing the linearity. 

